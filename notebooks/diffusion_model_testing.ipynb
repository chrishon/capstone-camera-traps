{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/chrishon/capstone-camera-traps.git\n",
        "%cd capstone-camera-traps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNMEFUN48qgq",
        "outputId": "3f0a291f-f6db-4736-b3c9-77eab4d4a9fe"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'capstone-camera-traps' already exists and is not an empty directory.\n",
            "/content/capstone-camera-traps\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "J6weGGN88pvo"
      },
      "outputs": [],
      "source": [
        "import video_processing\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "v2XpfbzV8pvp"
      },
      "outputs": [],
      "source": [
        "from video_processing.prepare_data import extract_frames, prepare_train_data, prepare_train_data_diffusion\n",
        "from video_processing.post_processing import predict_multiple_samples, multi_sample_frame_analysis, visualize_multiple_comparisons, multi_sample_temporal_analysis, temporal_analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9jFZucx-8pvq"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda') if  torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fbfhu9Cd8pvq",
        "outputId": "6fd67884-be1e-4566-e044-6f8268c0091f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "UNet2DModel(\n",
              "  (conv_in): Conv2d(18, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (time_proj): Timesteps()\n",
              "  (time_embedding): TimestepEmbedding(\n",
              "    (linear_1): Linear(in_features=128, out_features=512, bias=True)\n",
              "    (act): SiLU()\n",
              "    (linear_2): Linear(in_features=512, out_features=512, bias=True)\n",
              "  )\n",
              "  (down_blocks): ModuleList(\n",
              "    (0): DownBlock2D(\n",
              "      (resnets): ModuleList(\n",
              "        (0-1): 2 x ResnetBlock2D(\n",
              "          (norm1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
              "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (time_emb_proj): Linear(in_features=512, out_features=128, bias=True)\n",
              "          (norm2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (nonlinearity): SiLU()\n",
              "        )\n",
              "      )\n",
              "      (downsamplers): ModuleList(\n",
              "        (0): Downsample2D(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (1): DownBlock2D(\n",
              "      (resnets): ModuleList(\n",
              "        (0): ResnetBlock2D(\n",
              "          (norm1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
              "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (time_emb_proj): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (nonlinearity): SiLU()\n",
              "          (conv_shortcut): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (1): ResnetBlock2D(\n",
              "          (norm1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
              "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (time_emb_proj): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (nonlinearity): SiLU()\n",
              "        )\n",
              "      )\n",
              "      (downsamplers): ModuleList(\n",
              "        (0): Downsample2D(\n",
              "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (2): AttnDownBlock2D(\n",
              "      (attentions): ModuleList(\n",
              "        (0-1): 2 x Attention(\n",
              "          (group_norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
              "          (to_q): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (to_k): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (to_v): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (to_out): ModuleList(\n",
              "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (1): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (resnets): ModuleList(\n",
              "        (0): ResnetBlock2D(\n",
              "          (norm1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
              "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (time_emb_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (norm2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (nonlinearity): SiLU()\n",
              "          (conv_shortcut): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (1): ResnetBlock2D(\n",
              "          (norm1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
              "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (time_emb_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (norm2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (nonlinearity): SiLU()\n",
              "        )\n",
              "      )\n",
              "      (downsamplers): ModuleList(\n",
              "        (0): Downsample2D(\n",
              "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (3): AttnDownBlock2D(\n",
              "      (attentions): ModuleList(\n",
              "        (0-1): 2 x Attention(\n",
              "          (group_norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
              "          (to_q): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (to_k): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (to_v): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (to_out): ModuleList(\n",
              "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (1): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (resnets): ModuleList(\n",
              "        (0-1): 2 x ResnetBlock2D(\n",
              "          (norm1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
              "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (time_emb_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (norm2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (nonlinearity): SiLU()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (up_blocks): ModuleList(\n",
              "    (0): AttnUpBlock2D(\n",
              "      (attentions): ModuleList(\n",
              "        (0-2): 3 x Attention(\n",
              "          (group_norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
              "          (to_q): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (to_k): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (to_v): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (to_out): ModuleList(\n",
              "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (1): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (resnets): ModuleList(\n",
              "        (0-2): 3 x ResnetBlock2D(\n",
              "          (norm1): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
              "          (conv1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (time_emb_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (norm2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (nonlinearity): SiLU()\n",
              "          (conv_shortcut): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (upsamplers): ModuleList(\n",
              "        (0): Upsample2D(\n",
              "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (1): AttnUpBlock2D(\n",
              "      (attentions): ModuleList(\n",
              "        (0-2): 3 x Attention(\n",
              "          (group_norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
              "          (to_q): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (to_k): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (to_v): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (to_out): ModuleList(\n",
              "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (1): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (resnets): ModuleList(\n",
              "        (0-1): 2 x ResnetBlock2D(\n",
              "          (norm1): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
              "          (conv1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (time_emb_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (norm2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (nonlinearity): SiLU()\n",
              "          (conv_shortcut): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (2): ResnetBlock2D(\n",
              "          (norm1): GroupNorm(32, 768, eps=1e-05, affine=True)\n",
              "          (conv1): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (time_emb_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (norm2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (nonlinearity): SiLU()\n",
              "          (conv_shortcut): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (upsamplers): ModuleList(\n",
              "        (0): Upsample2D(\n",
              "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (2): UpBlock2D(\n",
              "      (resnets): ModuleList(\n",
              "        (0): ResnetBlock2D(\n",
              "          (norm1): GroupNorm(32, 768, eps=1e-05, affine=True)\n",
              "          (conv1): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (time_emb_proj): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (nonlinearity): SiLU()\n",
              "          (conv_shortcut): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (1): ResnetBlock2D(\n",
              "          (norm1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
              "          (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (time_emb_proj): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (nonlinearity): SiLU()\n",
              "          (conv_shortcut): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (2): ResnetBlock2D(\n",
              "          (norm1): GroupNorm(32, 384, eps=1e-05, affine=True)\n",
              "          (conv1): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (time_emb_proj): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (nonlinearity): SiLU()\n",
              "          (conv_shortcut): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (upsamplers): ModuleList(\n",
              "        (0): Upsample2D(\n",
              "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (3): UpBlock2D(\n",
              "      (resnets): ModuleList(\n",
              "        (0): ResnetBlock2D(\n",
              "          (norm1): GroupNorm(32, 384, eps=1e-05, affine=True)\n",
              "          (conv1): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (time_emb_proj): Linear(in_features=512, out_features=128, bias=True)\n",
              "          (norm2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (nonlinearity): SiLU()\n",
              "          (conv_shortcut): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (1-2): 2 x ResnetBlock2D(\n",
              "          (norm1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
              "          (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (time_emb_proj): Linear(in_features=512, out_features=128, bias=True)\n",
              "          (norm2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (nonlinearity): SiLU()\n",
              "          (conv_shortcut): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (mid_block): UNetMidBlock2D(\n",
              "    (attentions): ModuleList(\n",
              "      (0): Attention(\n",
              "        (group_norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
              "        (to_q): Linear(in_features=512, out_features=512, bias=True)\n",
              "        (to_k): Linear(in_features=512, out_features=512, bias=True)\n",
              "        (to_v): Linear(in_features=512, out_features=512, bias=True)\n",
              "        (to_out): ModuleList(\n",
              "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (1): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (resnets): ModuleList(\n",
              "      (0-1): 2 x ResnetBlock2D(\n",
              "        (norm1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (time_emb_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "        (norm2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (nonlinearity): SiLU()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (conv_norm_out): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
              "  (conv_act): SiLU()\n",
              "  (conv_out): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from diffusers import UNet2DModel\n",
        "\n",
        "model = UNet2DModel(\n",
        "    sample_size=64,\n",
        "    in_channels=3 + 5*3,  # Noisy image (3) + condition (5*3)\n",
        "    out_channels=3,       # Predict noise\n",
        "    layers_per_block=2,\n",
        "    block_out_channels=(128, 256, 512, 512),\n",
        "    down_block_types=(\n",
        "        \"DownBlock2D\", \"DownBlock2D\", \"AttnDownBlock2D\", \"AttnDownBlock2D\"\n",
        "    ),\n",
        "    up_block_types=(\n",
        "        \"AttnUpBlock2D\", \"AttnUpBlock2D\", \"UpBlock2D\", \"UpBlock2D\"\n",
        "    ),\n",
        ")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "V97M9wN48pvq"
      },
      "outputs": [],
      "source": [
        "from diffusers import DDPMScheduler\n",
        "\n",
        "noise_scheduler = DDPMScheduler(\n",
        "    num_train_timesteps=1000,\n",
        "    beta_start=0.0001,\n",
        "    beta_end=0.02,\n",
        "    beta_schedule=\"linear\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5mb2Q8pmk97h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_fQzIK886Xf",
        "outputId": "4afca083-c018-45e9-a937-4e0176ae2491"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XvyTRSes8pvq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MOssYW-D8pvq"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "# 1. Extract and prepare data\n",
        "video_path=\"/content/drive/MyDrive/capstone-camera-traps/resources/videos/FH102_02 (1).avi\"\n",
        "frames = extract_frames(video_path,size = (128,128))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "frames = frames[:5000]"
      ],
      "metadata": {
        "id": "9gKdx8OhARp9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sr-loH0C8pvr",
        "outputId": "ef4a0c29-229d-4b9e-c59f-440517f2eb7b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "len(frames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTgOoapY8pvr"
      },
      "outputs": [],
      "source": [
        "\n",
        "X_condition, y_target = prepare_train_data_diffusion(frames, sequence_length=5)\n",
        "\n",
        "# 2. Create dataloader\n",
        "X_tensor = torch.tensor(X_condition, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y_target, dtype=torch.float32)\n",
        "dataset = TensorDataset(X_tensor, y_tensor)\n",
        "train_loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "# 3. Verify shapes\n",
        "sample_batch = next(iter(train_loader))\n",
        "condition_batch, target_batch = sample_batch\n",
        "print(f\"Condition shape: {condition_batch.shape}\")  # Should be (batch, 15, 64, 64)\n",
        "print(f\"Target shape: {target_batch.shape}\")        # Should be (batch, 3, 64, 64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JifUZsu58pvr"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "num_epochs = 1\n",
        "for epoch in range(num_epochs):\n",
        "    i = 1\n",
        "    for batch_condition, batch_target in train_loader:\n",
        "        print(i)\n",
        "        i += 1\n",
        "        batch_condition = batch_condition.to(device)\n",
        "        batch_target = batch_target.to(device)\n",
        "\n",
        "        # Sample noise and timesteps\n",
        "        noise = torch.randn_like(batch_target)\n",
        "        timesteps = torch.randint(0, noise_scheduler.num_train_timesteps,\n",
        "                                 (batch_target.shape[0],), device=device)\n",
        "\n",
        "        # Add noise to targets\n",
        "        noisy_images = noise_scheduler.add_noise(batch_target, noise, timesteps)\n",
        "\n",
        "        # Combine with condition and predict noise\n",
        "        model_input = torch.cat([noisy_images, batch_condition], dim=1)\n",
        "        noise_pred = model(model_input, timesteps).sample\n",
        "\n",
        "        # Compute loss\n",
        "        loss = torch.nn.functional.mse_loss(noise_pred, noise)\n",
        "\n",
        "        # Optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1_PVtuM8pvr"
      },
      "outputs": [],
      "source": [
        "def predict_next_frame(model, condition, scheduler, device):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Initial noise\n",
        "        sample = torch.randn((1, 3, 64, 64), device=device)\n",
        "        condition = condition.unsqueeze(0).to(device)\n",
        "\n",
        "        # Denoising loop\n",
        "        for t in scheduler.timesteps:\n",
        "            model_input = torch.cat([sample, condition], dim=1)\n",
        "            noise_pred = model(model_input, t).sample\n",
        "            sample = scheduler.step(noise_pred, t, sample).prev_sample\n",
        "\n",
        "        # Denormalize and format\n",
        "        predicted_frame = sample.squeeze().cpu().numpy()\n",
        "        predicted_frame = (predicted_frame + 1) / 2  # [0, 1]\n",
        "        predicted_frame = np.transpose(predicted_frame, (1, 2, 0))\n",
        "        return predicted_frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvTX5Xv18pvr"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# Prepare test data\n",
        "X_condition_test, y_test = X_condition, y_target\n",
        "# X_condition_test, y_test = prepare_train_data(test_frames)\n",
        "\n",
        "# Select sample\n",
        "sample_idx = 3\n",
        "condition_sample = torch.tensor(X_condition_test[sample_idx], dtype=torch.float32)\n",
        "actual_frame = (y_test[sample_idx].transpose(1, 2, 0) + 1) / 2  # To HWC and [0,1]\n",
        "\n",
        "# Generate prediction\n",
        "predictions = predict_multiple_samples(model, condition_sample, noise_scheduler,\n",
        "                                      device, num_samples=5)\n",
        "\n",
        "actual_frame = (y_test[sample_idx].transpose(1, 2, 0) + 1) / 2\n",
        "\n",
        "# Analyze\n",
        "analysis = multi_sample_frame_analysis(predictions, actual_frame)\n",
        "\n",
        "# Plot\n",
        "visualize_multiple_comparisons(predictions, actual_frame)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_initial_condition(frames):\n",
        "    \"\"\"Convert initial frames to model input format\"\"\"\n",
        "    # Convert to numpy array and normalize\n",
        "    frames_np = np.array(frames) / 255.0 * 2 - 1  # [-1, 1] range\n",
        "\n",
        "    # Transpose to (seq_len, C, H, W)\n",
        "    frames_transposed = np.transpose(frames_np, (0, 3, 1, 2))\n",
        "\n",
        "    # Combine sequence length and channels\n",
        "    initial_condition = frames_transposed.reshape(1, -1, frames_np.shape[1], frames_np.shape[2])\n",
        "\n",
        "    return initial_condition\n"
      ],
      "metadata": {
        "id": "j1mugdK1hYhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_YhfLNPRclyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_sequence(\n",
        "    model,\n",
        "    initial_condition,\n",
        "    scheduler,\n",
        "    device,\n",
        "    num_frames=10,\n",
        "    sequence_length=5\n",
        "):\n",
        "    \"\"\"Generate a sequence of frames autoregressively\"\"\"\n",
        "    # Initial setup\n",
        "    current_condition = initial_condition.clone().to(device)\n",
        "    predicted_frames = []\n",
        "    C, H, W = 3, 64, 64  # Update if your resolution differs\n",
        "\n",
        "    for _ in range(num_frames):\n",
        "        # Predict next frame (returns tensor in [-1, 1])\n",
        "        next_frame = predict_next_frame_tensor(model, current_condition, scheduler, device)\n",
        "        predicted_frames.append(next_frame.cpu())\n",
        "\n",
        "        # Update condition: Remove oldest frame, add new prediction\n",
        "        current_condition = torch.cat([\n",
        "            current_condition[:, 3:],  # Remove oldest 3 channels\n",
        "            next_frame.unsqueeze(0)    # Add new prediction\n",
        "        ], dim=1)\n",
        "\n",
        "    # Denormalize and format\n",
        "    denorm_frames = [\n",
        "        (frame.squeeze().numpy().transpose(1, 2, 0) * 0.5 + 0.5)  # [-1,1] → [0,1]\n",
        "        for frame in predicted_frames\n",
        "    ]\n",
        "    return denorm_frames\n",
        "\n",
        "def predict_next_frame_tensor(model, condition, scheduler, device):\n",
        "    \"\"\"Diffusion prediction (returns tensor in [-1, 1])\"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        noise = torch.randn((1, 3, 64, 64), device=device)\n",
        "        condition = condition.to(device)\n",
        "\n",
        "        for t in scheduler.timesteps:\n",
        "            model_input = torch.cat([noise, condition], dim=1)\n",
        "            noise_pred = model(model_input, t).sample\n",
        "            noise = scheduler.step(noise_pred, t, noise).prev_sample\n",
        "\n",
        "        return noise.squeeze(0)  # (3, H, W)\n",
        "\n",
        "def get_gt_sequence(frames, start_idx, sequence_length=5, num_frames=10):\n",
        "    \"\"\"Extract ground truth sequence from original frames\"\"\"\n",
        "    # Get initial sequence and subsequent frames\n",
        "    initial_frames = frames[start_idx : start_idx + sequence_length]\n",
        "    gt_sequence = frames[start_idx + sequence_length : start_idx + sequence_length + num_frames]\n",
        "\n",
        "    # Convert to [0, 1] range\n",
        "    gt_sequence = [frame.astype(np.float32) / 255.0 for frame in gt_sequence]\n",
        "    return gt_sequence\n",
        "\n",
        "# Parameters\n",
        "sequence_length = 5\n",
        "num_pred_frames = 20\n",
        "start_idx = 0  # Starting point in video\n",
        "\n",
        "# Get initial frames for conditioning\n",
        "initial_frames = frames[start_idx : start_idx + sequence_length]\n",
        "\n",
        "# Prepare initial condition tensor\n",
        "initial_condition_np = prepare_initial_condition(initial_frames)\n",
        "initial_condition = torch.tensor(initial_condition_np, dtype=torch.float32).to(device)\n",
        "\n",
        "# Generate predicted sequence\n",
        "predicted_sequence = generate_sequence(\n",
        "    model,\n",
        "    initial_condition,\n",
        "    noise_scheduler,\n",
        "    device,\n",
        "    num_frames=num_pred_frames\n",
        ")\n",
        "\n",
        "# Get ground truth sequence\n",
        "gt_sequence = get_gt_sequence(\n",
        "    [f.astype(np.uint8) for f in frames],  # Original uint8 frames\n",
        "    start_idx,\n",
        "    num_frames=num_pred_frames\n",
        ")"
      ],
      "metadata": {
        "id": "dSLNHcto12At"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Analyze sequences\n",
        "pred_metrics = temporal_analysis(predicted_sequence)\n",
        "gt_metrics = temporal_analysis(gt_sequence)\n",
        "\n",
        "# Compare metrics\n",
        "def compare_metrics(pred, gt):\n",
        "    print(f\"{'Metric':<25} {'Predicted':<10} {'GT':<10} {'Diff':<10}\")\n",
        "    for key in pred:\n",
        "        p_val = np.mean(pred[key])\n",
        "        g_val = np.mean(gt[key])\n",
        "        print(f\"{key:<25} {p_val:.4f}     {g_val:.4f}     {abs(p_val - g_val):.4f}\")\n",
        "\n",
        "compare_metrics(pred_metrics, gt_metrics)"
      ],
      "metadata": {
        "id": "DYutDRW_fU-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_temporal_comparison(pred_metrics, gt_metrics):\n",
        "    fig, axs = plt.subplots(3, 1, figsize=(12, 8))\n",
        "    metrics = ['flow_magnitude', 'intensity_change', 'temporal_ssim']\n",
        "\n",
        "    for i, metric in enumerate(metrics):\n",
        "        axs[i].plot(pred_metrics[metric], label='Predicted')\n",
        "        axs[i].plot(gt_metrics[metric], label='Ground Truth')\n",
        "        axs[i].set_title(metric.replace('_', ' ').title())\n",
        "        axs[i].legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_temporal_comparison(pred_metrics, gt_metrics)"
      ],
      "metadata": {
        "id": "Hq4LASVefQOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wi8F7ngq8pvr"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "htqZ_xYG8pvs"
      },
      "outputs": [],
      "source": [
        "from video_processing.post_processing import frame_analysis, visualize_comparison, temporal_analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUI4v8-I8pvs"
      },
      "outputs": [],
      "source": [
        "analysis_results = frame_analysis(predicted_frame, actual_frame)\n",
        "analysis_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bN3BDzq38pvs"
      },
      "outputs": [],
      "source": [
        "visualize_comparison(predicted_frame, actual_frame)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MZpBfTL3hdXl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}